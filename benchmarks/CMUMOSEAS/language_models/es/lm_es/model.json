{
    "accum_grad": 1,
    "att_unit": 512,
    "backend": "pytorch",
    "beta1": 0.9,
    "beta2": 0.999,
    "char_list_dict": {
        "<blank>": 0,
        "<eos>": 36,
        "<space>": 2,
        "<unk>": 1,
        "a": 3,
        "b": 4,
        "c": 5,
        "d": 6,
        "e": 7,
        "f": 8,
        "g": 9,
        "h": 10,
        "i": 11,
        "j": 12,
        "k": 13,
        "l": 14,
        "m": 15,
        "n": 16,
        "o": 17,
        "p": 18,
        "q": 19,
        "r": 20,
        "s": 21,
        "t": 22,
        "u": 23,
        "v": 24,
        "w": 25,
        "x": 26,
        "y": 27,
        "z": 28,
        "á": 29,
        "é": 30,
        "í": 31,
        "ñ": 32,
        "ó": 33,
        "ú": 34,
        "ü": 35
    },
    "config2": null,
    "config3": null,
    "debugmode": 1,
    "dict": "data/lang_1char/train_es_units.txt",
    "dropout_rate": 0.0,
    "dump_hdf5_path": null,
    "early_stop_criterion": "validation/main/loss",
    "embed_unit": 128,
    "epoch": 50,
    "gradclip": 1.0,
    "head": 8,
    "layer": 16,
    "lr": 0.0001,
    "lr_cosine_total": 100000,
    "lr_cosine_warmup": 1000,
    "maxlen": 40,
    "model_module": "transformer",
    "n_vocab": 37,
    "ngpu": 1,
    "opt": "adam",
    "patience": 0,
    "pos_enc": "none",
    "report_interval_iters": 100,
    "schedulers": [
        [
            "lr",
            "cosine"
        ]
    ],
    "seed": 1,
    "sortagrad": 0,
    "test_label": null,
    "train_dtype": "float32",
    "unit": 2048,
    "verbose": 1,
    "weight_decay": 0.0
}